{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "warnings.filterwarnings('ignore')\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe for Input and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = []\n",
    "label = []\n",
    "main_class_names = ['Cat', 'Dog', 'Horse']\n",
    "image_path = 'images_download'\n",
    "\n",
    "for class_name in os.listdir(image_path):\n",
    "  for path in os.listdir(f'{image_path}/{class_name}'):\n",
    "    if class_name == 'Cat' and label.count(0) < 12498:\n",
    "      label.append(0)\n",
    "      input_path.append(os.path.join(f'{image_path}', class_name, path))\n",
    "    elif class_name == 'Dog' and label.count(1) < 12498:\n",
    "      label.append(1)\n",
    "      input_path.append(os.path.join(f'{image_path}', class_name, path))\n",
    "    elif class_name == 'Horse' and label.count(2) < 12498:\n",
    "      label.append(2)\n",
    "      input_path.append(os.path.join(f'{image_path}', class_name, path))\n",
    "      \n",
    "print(input_path[0], label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label.count(0))\n",
    "print(label.count(1))\n",
    "print(label.count(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_path[-1], label[-1])\n",
    "print()\n",
    "print(len(input_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Invalid Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in input_path:\n",
    "  try:\n",
    "    PIL.Image.open(image)\n",
    "  except:\n",
    "    print(image)\n",
    "    os.remove(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['images'] = input_path\n",
    "df['label'] = label\n",
    "df = df.sample(frac=1).reset_index(drop = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "# to display grid of images 'Dogs'\n",
    "plt.figure(figsize=(25,25))\n",
    "temp = df[df['label']==1]['images']\n",
    "start = random.randint(0, len(temp))\n",
    "files = temp[start:start+25]\n",
    "\n",
    "for index, file in enumerate(files):\n",
    "  plt.subplot(5,5, index+1)\n",
    "  img = load_img(file)\n",
    "  img = np.array(img)\n",
    "  plt.imshow(img)\n",
    "  plt.title('Dogs')\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "# to display grid of images 'Cats'\n",
    "plt.figure(figsize=(25,25))\n",
    "temp = df[df['label']==0]['images']\n",
    "start = random.randint(0, len(temp))\n",
    "files = temp[start:start+25]\n",
    "\n",
    "for index, file in enumerate(files):\n",
    "  plt.subplot(5,5, index+1)\n",
    "  img = load_img(file)\n",
    "  img = np.array(img)\n",
    "  plt.imshow(img)\n",
    "  plt.title('Cats')\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "\n",
    "# to display grid of images 'Horses'\n",
    "plt.figure(figsize=(25,25))\n",
    "temp = df[df['label']==2]['images']\n",
    "start = random.randint(0, len(temp))\n",
    "files = temp[start:start+25]\n",
    "\n",
    "for index, file in enumerate(files):\n",
    "  plt.subplot(5,5, index+1)\n",
    "  img = load_img(file)\n",
    "  img = np.array(img)\n",
    "  plt.imshow(img)\n",
    "  plt.title('Horses')\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataGenerator for the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].astype('str')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_generator = ImageDataGenerator(\n",
    "    rescale = 1./255, # normalization of images\n",
    "    rotation_range = 40, ## augmention of images to avoid overfitting\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_iterator = train_generator.flow_from_dataframe(\n",
    "    train,\n",
    "    x_col='images',\n",
    "    y_col='label',\n",
    "    target_size=(128,128),\n",
    "    batch_size=512,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_iterator = val_generator.flow_from_dataframe(\n",
    "    test,\n",
    "    x_col='images',\n",
    "    y_col='label',\n",
    "    target_size=(128,128),\n",
    "    batch_size=512,\n",
    "    class_mode='categorical')\n",
    "\n",
    "print(len(train_iterator))\n",
    "print(len(val_iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "                   \n",
    "    # Option 1\n",
    "    Conv2D(16, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPool2D((2, 2)),\n",
    "    \n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPool2D((2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPool2D((2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "\n",
    "\n",
    "    # Option 2\n",
    "    # Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    # MaxPool2D((2, 2)),\n",
    "    \n",
    "    # Conv2D(64, (3, 3), activation='relu'),\n",
    "    # MaxPool2D((2, 2)),\n",
    "    \n",
    "    # Conv2D(128, (3, 3), activation='relu'),\n",
    "    # MaxPool2D((2, 2)),\n",
    "    \n",
    "    # Flatten(),\n",
    "    # Dense(128, activation='relu'),\n",
    "    # Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_iterator, epochs=10, validation_data=val_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/my_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_name = f\"models/my_model_{current_time}.keras\"\n",
    "model.save(model_name)\n",
    "\n",
    "print(f\"Model saved as: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('models/my_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Accuracy Graph')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Loss Graph')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificate own pictures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Existing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"validation_images\" \n",
    "\n",
    "validation_full_paths = []\n",
    "\n",
    "if os.path.exists(directory_path):\n",
    "    for i_path in os.listdir(directory_path):\n",
    "        full_path = os.path.join(directory_path, i_path)\n",
    "        validation_full_paths.append(full_path) \n",
    "else:\n",
    "    print(f\"The directory '{directory_path}' does not exist.\")\n",
    "\n",
    "for path in validation_full_paths:\n",
    "    print(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "directory_path = \"validation_images/\" \n",
    "\n",
    "testing_array = []\n",
    "full_paths = []\n",
    "testing_img = []\n",
    "prediction_array = []\n",
    "\n",
    "for i_path in os.listdir(directory_path):\n",
    "  try:\n",
    "    full_path = directory_path +  i_path\n",
    "    if os.path.isfile(full_path): \n",
    "      full_paths.append(full_path)\n",
    "      img = image.load_img(full_path, target_size=(128, 128))\n",
    "      testing_img.append(img)\n",
    "  except Exception as e:\n",
    "    print(\"An error occurred: \" + full_path, e)\n",
    "\n",
    "print(os.listdir(directory_path))\n",
    "print(full_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 0\n",
    "trueCalculation = 0\n",
    "falseCalculation = 0\n",
    "false_calculation_path = []\n",
    "main_class_names = ['Cat', 'Dog', 'Horse']\n",
    "\n",
    "\n",
    "for path in full_paths:\n",
    "    img = image.load_img(path, target_size=(128,128))\n",
    "    img_array = image.img_to_array(img) / 255. # convert img to Numpy-Array\n",
    "    img_array = np.expand_dims(img_array, axis=0) # add dimension\n",
    "\n",
    "    prediction = model.predict(img_array) # predict\n",
    "    print(prediction)\n",
    "    prediction_array.append(prediction)\n",
    "\n",
    "    prediction_array_test = np.array(prediction)\n",
    "    predicted_class = np.argmax(prediction_array_test)\n",
    "    print(f\"Path: {path}  => Prediction: {main_class_names[predicted_class]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
